{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Cài đặt các thư viện cần thiết trên Kaggle\n",
    "!pip install transformers torch pandas numpy rouge-score bert-score huggingface_hub\n",
    "\n",
    "# 2. Đăng nhập vào Hugging Face để tải mô hình\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Dán API Token của bạn (lấy từ Hugging Face Settings > Access Tokens)\n",
    "api_token = \"\"  # Thay bằng API Token của bạn\n",
    "login(api_token)\n",
    "\n",
    "# 3. Tải mô hình và tokenizer từ Hugging Face\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, GenerationConfig\n",
    "\n",
    "repo_id = \"HTThuanHcmus/bart-finetuned-scientific\"  # Thay bằng username và tên repo của bạn\n",
    "tokenizer = BartTokenizer.from_pretrained(repo_id)\n",
    "model = BartForConditionalGeneration.from_pretrained(repo_id)\n",
    "\n",
    "# Tạo GenerationConfig thủ công để tránh lỗi\n",
    "generation_config = GenerationConfig(\n",
    "    early_stopping=True,\n",
    "    max_length=32,\n",
    "    num_beams=5\n",
    ")\n",
    "model.generation_config = generation_config\n",
    "\n",
    "# 4. Hàm dự đoán tiêu đề từ abstract bằng BART\n",
    "def predict_title_bart(abstract):\n",
    "    inputs = tokenizer(abstract, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=32,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        decoder_start_token_id=tokenizer.bos_token_id if tokenizer.bos_token_id is not None else tokenizer.convert_tokens_to_ids('<s>')\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 5. Tải dữ liệu test trên Kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "\n",
    "# Giả sử dữ liệu của bạn nằm trong /kaggle/input\n",
    "# File CSV chứa các cột: abstract, title (tiêu đề thực tế), llm_title (tiêu đề từ LLM)\n",
    "data_df = pd.read_csv('/kaggle/input/compare-bart-llm/random_500_samples_full.csv')  # Thay bằng đường dẫn thực tế trên Kaggle\n",
    "abstracts = data_df['abstract'].tolist()\n",
    "true_titles = data_df['title'].tolist()\n",
    "llm_titles = data_df['title-llm'].tolist()\n",
    "\n",
    "# 6. Dự đoán tiêu đề bằng BART\n",
    "bart_titles = [predict_title_bart(abs) for abs in abstracts]\n",
    "\n",
    "# 7. Tính ROUGE và BERTScore cho cả hai tập tiêu đề\n",
    "# ROUGE\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "# ROUGE cho LLM\n",
    "llm_rouge1_scores = []\n",
    "llm_rouge2_scores = []\n",
    "llm_rougeL_scores = []\n",
    "llm_rougeLsum_scores = []\n",
    "\n",
    "for pred, ref in zip(llm_titles, true_titles):\n",
    "    scores = scorer.score(ref, pred)\n",
    "    llm_rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "    llm_rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "    llm_rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "    llm_rougeLsum_scores.append(scores['rougeLsum'].fmeasure)\n",
    "\n",
    "# ROUGE cho BART\n",
    "bart_rouge1_scores = []\n",
    "bart_rouge2_scores = []\n",
    "bart_rougeL_scores = []\n",
    "bart_rougeLsum_scores = []\n",
    "\n",
    "for pred, ref in zip(bart_titles, true_titles):\n",
    "    scores = scorer.score(ref, pred)\n",
    "    bart_rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "    bart_rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "    bart_rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "    bart_rougeLsum_scores.append(scores['rougeLsum'].fmeasure)\n",
    "\n",
    "# BERTScore cho LLM\n",
    "llm_P, llm_R, llm_F1 = score(llm_titles, true_titles, lang=\"en\", verbose=True)\n",
    "llm_bert_precision_scores = llm_P.tolist()\n",
    "llm_bert_recall_scores = llm_R.tolist()\n",
    "llm_bert_f1_scores = llm_F1.tolist()\n",
    "\n",
    "# BERTScore cho BART\n",
    "bart_P, bart_R, bart_F1 = score(bart_titles, true_titles, lang=\"en\", verbose=True)\n",
    "bart_bert_precision_scores = bart_P.tolist()\n",
    "bart_bert_recall_scores = bart_R.tolist()\n",
    "bart_bert_f1_scores = bart_F1.tolist()\n",
    "\n",
    "# 8. So sánh trung bình ROUGE và BERTScore\n",
    "print(\"So sánh trung bình ROUGE và BERTScore:\\n\")\n",
    "\n",
    "print(\"LLM Titles:\")\n",
    "print(f\"ROUGE-1: {np.mean(llm_rouge1_scores):.4f}\")\n",
    "print(f\"ROUGE-2: {np.mean(llm_rouge2_scores):.4f}\")\n",
    "print(f\"ROUGE-L: {np.mean(llm_rougeL_scores):.4f}\")\n",
    "print(f\"ROUGE-Lsum: {np.mean(llm_rougeLsum_scores):.4f}\")\n",
    "print(f\"BERTScore Precision: {np.mean(llm_bert_precision_scores):.4f}\")\n",
    "print(f\"BERTScore Recall: {np.mean(llm_bert_recall_scores):.4f}\")\n",
    "print(f\"BERTScore F1: {np.mean(llm_bert_f1_scores):.4f}\\n\")\n",
    "\n",
    "print(\"BART Fine-tuned Titles:\")\n",
    "print(f\"ROUGE-1: {np.mean(bart_rouge1_scores):.4f}\")\n",
    "print(f\"ROUGE-2: {np.mean(bart_rouge2_scores):.4f}\")\n",
    "print(f\"ROUGE-L: {np.mean(bart_rougeL_scores):.4f}\")\n",
    "print(f\"ROUGE-Lsum: {np.mean(bart_rougeLsum_scores):.4f}\")\n",
    "print(f\"BERTScore Precision: {np.mean(bart_bert_precision_scores):.4f}\")\n",
    "print(f\"BERTScore Recall: {np.mean(bart_bert_recall_scores):.4f}\")\n",
    "print(f\"BERTScore F1: {np.mean(bart_bert_f1_scores):.4f}\\n\")\n",
    "\n",
    "# 9. Phân tích chi tiết: Số lượng tiêu đề mà BART vượt trội hơn LLM và ngược lại\n",
    "bart_better_rouge1 = sum(1 for llm_score, bart_score in zip(llm_rouge1_scores, bart_rouge1_scores) if bart_score > llm_score)\n",
    "llm_better_rouge1 = sum(1 for llm_score, bart_score in zip(llm_rouge1_scores, bart_rouge1_scores) if llm_score > bart_score)\n",
    "\n",
    "bart_better_bertscore = sum(1 for llm_score, bart_score in zip(llm_bert_f1_scores, bart_bert_f1_scores) if bart_score > llm_score)\n",
    "llm_better_bertscore = sum(1 for llm_score, bart_score in zip(llm_bert_f1_scores, bart_bert_f1_scores) if llm_score > bart_score)\n",
    "\n",
    "print(\"Phân tích chi tiết:\")\n",
    "print(f\"Số tiêu đề mà BART có ROUGE-1 cao hơn LLM: {bart_better_rouge1}\")\n",
    "print(f\"Số tiêu đề mà LLM có ROUGE-1 cao hơn BART: {llm_better_rouge1}\")\n",
    "print(f\"Số tiêu đề mà BART có BERTScore F1 cao hơn LLM: {bart_better_bertscore}\")\n",
    "print(f\"Số tiêu đề mà LLM có BERTScore F1 cao hơn BART: {llm_better_bertscore}\\n\")\n",
    "\n",
    "# 10. Lưu kết quả chi tiết vào file CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'abstract': abstracts,\n",
    "    'true_title': true_titles,\n",
    "    'llm_title': llm_titles,\n",
    "    'bart_title': bart_titles,\n",
    "    'llm_rouge1': llm_rouge1_scores,\n",
    "    'llm_rouge2': llm_rouge2_scores,\n",
    "    'llm_rougeL': llm_rougeL_scores,\n",
    "    'llm_rougeLsum': llm_rougeLsum_scores,\n",
    "    'llm_bertscore_precision': llm_bert_precision_scores,\n",
    "    'llm_bertscore_recall': llm_bert_recall_scores,\n",
    "    'llm_bertscore_f1': llm_bert_f1_scores,\n",
    "    'bart_rouge1': bart_rouge1_scores,\n",
    "    'bart_rouge2': bart_rouge2_scores,\n",
    "    'bart_rougeL': bart_rougeL_scores,\n",
    "    'bart_rougeLsum': bart_rougeLsum_scores,\n",
    "    'bart_bertscore_precision': bart_bert_precision_scores,\n",
    "    'bart_bertscore_recall': bart_bert_recall_scores,\n",
    "    'bart_bertscore_f1': bart_bert_f1_scores\n",
    "})\n",
    "results_df.to_csv('/kaggle/working/comparison_results.csv', index=False)\n",
    "print(\"Đã lưu kết quả chi tiết vào '/kaggle/working/comparison_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7012787,
     "sourceId": 11227731,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
