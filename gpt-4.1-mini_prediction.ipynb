{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bb585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e85ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "from    dotenv import load_dotenv\n",
    "from    openai import OpenAI\n",
    "import  pandas as pd\n",
    "import  json\n",
    "import  numpy as np\n",
    "# Set up OpenAI API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1370f2e",
   "metadata": {},
   "source": [
    "### Prepare `.jsonl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efba72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2851,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiamatt/miniconda3/envs/py313_env/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "samples = pd.read_csv('./data/test.csv', encoding='utf-8')\n",
    "samples = samples[\"abstract\"]\n",
    "\n",
    "parts = np.array_split(samples, 2)\n",
    "\n",
    "print(parts[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d64d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Write a short, formal and structured title for this scientific research work, return ONLY the title: \"\n",
    "\n",
    "def write_to_jsonl(samples, partname):\n",
    "    with open(f\"./batches/batch_input_{partname}.jsonl\", \"w\") as f:\n",
    "        for i, abstract in enumerate(samples):\n",
    "            prompt = f\"{instruction}\\n\\n{abstract}\"\n",
    "            entry = {\n",
    "                \"custom_id\": f\"sample_{i}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4.1-mini\",\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"temperature\": 1.0,\n",
    "                    \"max_tokens\": 48\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c18f2c",
   "metadata": {},
   "source": [
    "### Upload file via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bcb7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(filename):\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(\"./batches/\" + filename, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    return batch_input_file.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a1462",
   "metadata": {},
   "source": [
    "### Submit the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d78b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_batch_job(file_id):\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "    batch_job = batch_job.__dict__\n",
    "    return batch_job['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b584cc",
   "metadata": {},
   "source": [
    "### Monitor status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad72483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_status(batch_job_id):\n",
    "        batch = client.batches.retrieve(batch_job_id).__dict__\n",
    "        status  = batch['status']\n",
    "        if status == \"completed\":\n",
    "            output_file_id = batch['output_file_id']\n",
    "            print(f\"Batch job ID: {batch_job_id}, Output file ID: {output_file_id}\")\n",
    "            return output_file_id, True\n",
    "        elif status == \"failed\":\n",
    "            raise Exception(f\"[{batch_job_id}]\",batch[\"errors\"])\n",
    "        else:\n",
    "            return None, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bdb7a",
   "metadata": {},
   "source": [
    "### Retrieve result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7e7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_result(output_file_id):\n",
    "    if output_file_id is None:\n",
    "        print(\"output _file_id was null\")\n",
    "        return\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(\"./output/\", exist_ok=True)\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    filename = f\"./output/{output_file_id}.jsonl\"\n",
    "    with open(filename, \"w\")  as f:\n",
    "        f.write(file_response.text)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f3f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_df(filename):\n",
    "    record = []\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = json.loads(line)\n",
    "            record.append(line[\"response\"]['body'][\"choices\"][0][\"message\"]['content'].strip(\"\\\"\"))\n",
    "    return pd.DataFrame(record, columns=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43cc3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(part, partname):\n",
    "    write_to_jsonl(part, partname)\n",
    "    print(f\"[{partname}] File written to .jsonl\")\n",
    "\n",
    "    file_id = upload(f\"batch_input_{partname}.jsonl\")\n",
    "    print(f\"[{partname}] File uploaded, file_id: {file_id}\")\n",
    "\n",
    "    bj_id = submit_batch_job(file_id)\n",
    "    print(f\"[{partname}] Batch job submitted, batch_job_id: {bj_id}\")\n",
    "\n",
    "    while True:\n",
    "        output_file_id, status = fetch_status(bj_id)\n",
    "        if status:\n",
    "            break\n",
    "    print(f\"[{partname}] Processing completed, output_file_id: {output_file_id}\")\n",
    "\n",
    "    filename = retrieve_result(output_file_id)\n",
    "    print(\"Saved output to\", filename)\n",
    "\n",
    "    return to_df(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] File written to .jsonl\n",
      "[0] File uploaded, file_id: file-9pAJVGCd5bhauCEvWxWC5U\n",
      "[0] Batch job submitted, batch_job_id: batch_67ffbe8926208190867cfee9f45d5539\n",
      "Batch job ID: batch_67ffbe8926208190867cfee9f45d5539, Output file ID: file-6WGi2mLG1jkyWXyHXA7hGB\n",
      "[0] Processing completed, output_file_id: file-6WGi2mLG1jkyWXyHXA7hGB\n",
      "Saved output to ./output/file-6WGi2mLG1jkyWXyHXA7hGB.jsonl\n",
      "[1] File written to .jsonl\n",
      "[1] File uploaded, file_id: file-Qa2NQJ2hGV6bKVESm5vDb1\n",
      "[1] Batch job submitted, batch_job_id: batch_67ffcc63ad9c8190b9f7888cbeab323a\n",
      "Batch job ID: batch_67ffcc63ad9c8190b9f7888cbeab323a, Output file ID: file-NqqasA1b2JiJzbSnmcFXLz\n",
      "[1] Processing completed, output_file_id: file-NqqasA1b2JiJzbSnmcFXLz\n",
      "Saved output to ./output/file-NqqasA1b2JiJzbSnmcFXLz.jsonl\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i,part in enumerate(parts):\n",
    "    df = pd.concat([df, run(part,i)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9703c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"abstract\": \"title\"}, inplace=True)\n",
    "df.to_csv(\"./output/gpt-4o-mini-output.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
